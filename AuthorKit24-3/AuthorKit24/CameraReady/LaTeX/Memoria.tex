%File: formatting-instructions-latex-2024.tex
%release 2024.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
\title{Hierarchical Reinforcement Learning: Maze with Tasks}
\author {
    % Authors
    Rubén Cid Costa\textsuperscript{\rm 1},
    Aimar Nicuera Usandizaga\textsuperscript{\rm 2},
    Daniel Obreo Sanz\textsuperscript{\rm 3}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1, \rm 2, \rm 3}Universidad Carlos III de Madrid\\
    
    \textsuperscript{\rm 1}100538592@alumnos.uc3m.es, 
    \textsuperscript{\rm 2}100538592@alumnos.uc3m.es, 
    \textsuperscript{\rm 3}100538592@alumnos.uc3m.es 
}


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
La realización de objetivos secuenciales en un entorno es una tarea compleja de modelar y aprender. Para poder representar estos
escenarios, una de las técnicas más usadas es el Aprendizaje por Refuerzo Jerárquico (\textit{Hierarchical Reinforcement Learning (HIL)}).
En este contexto, este trabajo se enfoca en Feudal Learning, una variante de IRL que organiza las tareas en una estructura jerárquica de
niveles de abstracción. Este documento detallará las bases teóricas y su aplicación sobre un ambiente de desarrollo con tareas de navegación y
obtención de subobjetivos.
\end{abstract}

\section{Introducción}

En muchos dominios, como la robótica o sistemas autónomos, las tareas implican la realización de objetivos secuenciales en entornos complejos.
La capacidad de modelar y aprender estos escenarios es un desafío crucial para la inteligencia artificial.

El aprendizaje por refuerzo jerárquico (HIL) se presenta como un enfoque para la resolución de estos problemas. Mientras que otras técnicas previas
enfrentan dificultades para escalar con el número de tareas y su complejidad, el Aprendizaje por Refuerzo Jerárquico (HIL) organiza el proceso en 
niveles de abstracción. Dentro de este marco, el Aprendizaje Feudal se presenta como un enfoque que permite modelar las tareas mediante un jerarquía
de abstracción.

Este trabajo se centra en el estudio de Feudal Learning, una variante de HIL. Se presentan las bases teóricas de esta técnica como diferentes algoritmos
o métodos de aprendizaje que se han desarrollado en este campo. También, se mostrará su aplicación sobre un entorno simulado diseñado para tareas 
de navegación en laberintos y obtención de subobjetivos. 

\section{Marco Teórico y Estado del Arte}
% Que es el aprendizaje jerárquico

% Qué el aprendizaje feudal

% Cómo se diferencia del aprendizaje normal

De manera general, el aprendizaje jerárquico 

\subsection{Sistemas de Control Feudal}
% Que son

% En que se fundamente
% - reward hiding
% - information hiding

\subsection{FeUdal Networks: FuN}

Las redes feudales se basan en la arquitectura de aprendiaje por refuerzo feudal, 
una arquitectura del aprendizaje por refuerzo jerárquico. Esta arquitectura emplea un sistema de control, conocido
como "manager", que asigna tareas a un subsistema conocido como "worker" que debe aprender a ejecutarlas de manera óptima.

La arquitectura del sistema se muestra en la imagen siguiente \cite{feudal_networks_2024}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\columnwidth]{feudal_arquitecture.png}
    \caption{Arquitectura de una red feudal.}
    \label{fig:arquitectura_feudal}
\end{figure}

La entrada de esta red es procesada por una capa de percepción, que emplea capas convolucionales
para extraer características de la imagen de entrada. A continuación, estas características son procesadas
tanto por el worker como por el manager, cada uno de manera distinta; el manager extrae objetivos y el worker
aprende a alcanzar esos objetivos.

El objetivo principal del manager es generar metas que el worker debe cumplir. Recibe la percepción
del entorno, proporcionada por el módulo de percepción, ese estado es procesado por una red recurrente LSTM
para mantener un estado interno y poder capturar información relevante en horizontes temporales largos.
El manager emplea esta información para predecir un objetivo direccional en el espacio latente, este objetivo
es un vector unitario, lo que asegura que el worker se enfoque en la dirección y no en la posición absoluta.

Para entrenar el manager, se emplea la recompensa obtenida, y emplea la similitud coseno entre la dirección en la que 
se movió el worker y la compara con el objetivo establecido, empleando la similitud coseno como función de pérdida.
Esta pérdida incentiva al Manager a emitir objetivos que maximicen el progreso hacia estados ventajosos.

El vector de objetivos se envía al worker sin propagar gradientes, esto garantiza que los objetivos 
mantengan un significado semántico independiente, en lugar de ser simples variables latentes optimizadas de manera conjunta.

En el caso del worker, también se emplea una red LSTM para mantener un estado interno y poder capturar información relevante,
pero en este caso, el worker recibe tanto la percepción del entorno como el objetivo del manager. El worker emplea esta información
para predecir la acción que debe realizar para alcanzar el objetivo. La acción se predice en el espacio de acciones, y se emplea


\subsection{Definición}

\subsection{Estado del arte}

\section{Evaluación práctica}

\section{Conclusiones}





\bibliography{aaai24}

\end{document}
